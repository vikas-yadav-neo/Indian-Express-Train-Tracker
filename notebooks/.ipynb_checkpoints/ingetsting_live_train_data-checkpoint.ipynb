{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c1b49-f757-4231-a833-4d450f8eb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125205ed-c64c-43d8-a737-e54f3e6a6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, IntegerType,\n",
    "    TimestampType, ArrayType\n",
    ")\n",
    "from pyspark.sql.functions import col, to_timestamp, lit, coalesce\n",
    "import psycopg2\n",
    "from pprint import pprint\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec02e96f-c960-445c-b93d-49028ddaef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORKERS = 10\n",
    "API_TIMEOUT = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626f138b-1ba6-4c6a-b843-6573580c35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"TrainNumbersPushToKafka\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.postgresql:postgresql:42.7.4,\"\n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5b3af4-2e73-4feb-8687-64c0183cc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19-08-2025 19_08_2025\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = \"https://easy-rail.onrender.com/fetch-train-status\"\n",
    "date_str = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "date_str_api = date_str\n",
    "date_str_table = date_str.replace('-', '_')\n",
    "print(date_str, date_str_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6ab8fe-b7ee-4144-b374-af9fb4a61f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JDBC_URL = \"jdbc:postgresql://postgres:5432/railway\"\n",
    "DB_PROPERTIES = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"iaCkmHPhuyhFLEBDGdwxQGGqlHvdgWJA\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37106e08-7cac-4205-a04a-6e1c0ad4fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgres_tables(jdbc_url, db_properties):\n",
    "    import psycopg2\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"postgres\",\n",
    "        port=5432,\n",
    "        dbname=\"railway\",\n",
    "        user=db_properties[\"user\"],\n",
    "        password=db_properties[\"password\"]\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema='public' AND table_type='BASE TABLE';\n",
    "    \"\"\")\n",
    "    tables = [row[0] for row in cur.fetchall()]\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f9b08-af11-482d-b770-d036816ee110",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = get_postgres_tables(JDBC_URL, DB_PROPERTIES)\n",
    "print(\"Found tables:\", tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d716c-fcd7-43c1-87e4-13a2e13ea3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_train(train_number: str, date_str: str):\n",
    "    if not train_number or not isinstance(train_number, str) or len(train_number) != 5:\n",
    "        return {\"success\": False, \"error\": \"Invalid train number. It must be a 5-character string.\"}\n",
    "\n",
    "    if not re.match(r\"^\\d{2}-\\d{2}-\\d{4}$\", date_str):\n",
    "        return {\"success\": False, \"error\": \"Invalid date format. Please use dd-mm-yyyy format.\"}\n",
    "\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(date_str, \"%d-%m-%Y\")\n",
    "        if parsed_date.strftime(\"%d-%m-%Y\") != date_str:\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        return {\"success\": False, \"error\": \"Invalid date. Please check the day, month, and year values.\"}\n",
    "\n",
    "    url = \"https://easy-rail.onrender.com/fetch-train-status\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "    }\n",
    "    payload = {\"trainNumber\": train_number, \"dates\": date_str}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if not data:\n",
    "            return {\"success\": False, \"error\": data.get(\"error\", \"Failed to fetch train status\")}\n",
    "        return {\"success\": True, \"data\": data}\n",
    "    except requests.RequestException as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "def parse_train_status(train_number, api_data):\n",
    "    if not api_data or not api_data.get(\"success\"):\n",
    "        print(f\"[WARN] Skipping train {train_number}, API did not return success\")\n",
    "        return None\n",
    "\n",
    "    stations = api_data.get(\"data\", [])\n",
    "    last_crossed = None\n",
    "    next_upcoming = None\n",
    "    delay_minutes = 0\n",
    "\n",
    "    for s in stations:\n",
    "        if s.get(\"status\") == \"crossed\":\n",
    "            last_crossed = s.get(\"station\")\n",
    "        elif s.get(\"status\") == \"upcoming\" and next_upcoming is None:\n",
    "            next_upcoming = s.get(\"station\")\n",
    "            match = re.search(r\"\\d+\", str(s.get(\"delay\", \"\")))\n",
    "            delay_minutes = int(match.group()) if match else 0\n",
    "            break\n",
    "\n",
    "    print(f\"[OK] Processed train {train_number} | Last crossed: {last_crossed} | Next: {next_upcoming} | Delay: {delay_minutes}m\")\n",
    "    return Row(train_number=train_number, last_crossed=last_crossed, next_upcoming=next_upcoming, delay_minutes=delay_minutes)\n",
    "\n",
    "def process_partition(partition):\n",
    "    date_str = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(process_train, row, date_str): row for row in partition}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.append(result)\n",
    "\n",
    "    return results  \n",
    "\n",
    "def process_train(row, date_str):\n",
    "    train_number = \"\".join(re.findall(r\"\\d+\", str(row.train_number)))\n",
    "    api_data = track_train(train_number, date_str)\n",
    "    return parse_train_status(train_number, api_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f115d53-5868-48de-8ed2-502d97e41cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_df = spark.read \\\n",
    "    .jdbc(url=JDBC_URL, table=\"trains\", properties=DB_PROPERTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e6591-e4b3-443d-9998-8850b583a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df = spark.read \\\n",
    "    .jdbc(url=JDBC_URL, table=\"stations\", properties=DB_PROPERTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9560a57-5538-4d79-9e8f-5987ffc2d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules_df = spark.read \\\n",
    "    .jdbc(url=JDBC_URL, table=\"schedules\", properties=DB_PROPERTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa673c-9312-4bc1-814c-d646d5157831",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_status_trains_df = spark.read \\\n",
    "    .jdbc(url=JDBC_URL, table=\"live_status\", properties=DB_PROPERTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be39e2e-6df3-44f3-8839-d067677af05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_status_df = trains_df.rdd.mapPartitions(process_partition).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2922652-d2cc-4d81-bf7c-01fe078b9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c422d44e-1089-4e0c-9788-d08eef2669cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_df = trains_df.select(\n",
    "    col(\"train_number\").cast(\"string\").alias(\"value\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1133516-1e3b-4139-bb91-1cf7ab8c4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_df.write \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"topic\", \"train-numbers\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb81082-1002-4fa1-9fb7-7fd891bec807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
